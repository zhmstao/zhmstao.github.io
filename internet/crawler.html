<!DOCTYPE html>
<html>

<head>
    <title>zhgt</title>
    <meta charset="utf-8">
    <meta content="width=device-width,initial-scale=1.0,max-scale=1.0,userscalable=0" name="viewport">
    <link rel="stylesheet" type="text/css" href="../layout.css">
</head>

<body>
    <header><a href="../index.html">张涛的学习笔记</a></header>
    <aside class="d-grid-3">
        <ul>
            <a href="#tag1">
                <li>获取segmentfault博客标题</li>
            </a>
            <a href="#tag2">
                <li>获取糗事百科段子</li>
            </a>
            <a href="#tag3">
                <li>测试node爬虫的可用性</li>
            </a>
            <a href="#tag4">
                <li>获取慕课网node教程的标题</li>
            </a>
        </ul>
    </aside>
    <section class="m-grid-4 d-grid-7 d-grid-offset-3">
        <h1>网络数据采集--编写爬虫</h1>
        <h2 id="tag1">使用python获取segmentfault推荐的博客标题</h2>
        <pre>
    #by zhangtao
    #coding:utf-8
    import urllib
    import urllib2
    import re
    url = "https://segmentfault.com/blogs"
    headers = { 'Host' : 'segmentfault.com',
                'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64) 
                                AppleWebKit/537.36 (KHTML, like Gecko) 
                                Chrome/50.0.2661.102 Safari/537.36',
                 'Referer':'https://segmentfault.com/blogs'} 
    #构建请求的request
    request = urllib2.Request(url=url,headers=headers)
    #利用urlopen获取页面代码
    response = urllib2.urlopen(request)
    #利用正则表达式确定匹配
    pattern = re.compile(' &lt;h2 class="title"&gt;&lt;a href="/a/.*?"&gt;(.*?)&lt;/a&gt;&lt;/h2&gt;',re.S)
    #找出所有的符合该模式的语句
    items = re.findall(pattern,response.read())
    #遍历输出
    for item in items:
    	print item
    	print 
		</pre>
        <h2 id="tag2">使用python获取糗事百科段子</h2>
        <pre>
#-*- coding:utf-8 -*-
import urllib
import urllib2
import re
import thread
import time

#糗事百科爬虫类
class QSBK:

	#初始化方法，定义一些变量
	def __init__(self):
		self.pageIndex = 1
		self.user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'
		#初始化headers
		self.headers = { 'User-Agent' : self.user_agent }
		#存放段子的变量，每一个元素是每一页的段子们
		self.stories = []
		#存放程序是否继续运行的变量
		self.enable = False
		#传入某一页的索引获得页面代码
	def getPage(self,pageIndex):
		try:
			url = 'http://www.qiushibaike.com/hot/page/' + str(pageIndex)
			#构建请求的request
			request = urllib2.Request(url,headers = self.headers)
			#利用urlopen获取页面代码
			response = urllib2.urlopen(request)
			#将页面转化为UTF-8编码
			pageCode = response.read().decode('utf-8')
			return pageCode
	
		except urllib2.URLError, e:
			if hasattr(e,"reason"):
				print u"连接糗事百科失败,错误原因",e.reason
				return None
	

	#传入某一页代码，返回本页不带图片的段子列表
	def getPageItems(self,pageIndex):
		pageCode = self.getPage(pageIndex)
		if not pageCode:
			print "页面加载失败...."
			return None
		pattern = re.compile('&lt;div class="author clearfix"&gt;.*?href.*?&lt;img src.*?title=.*?&gt;
		&lt;h2&gt;(.*?)&lt;/h2&gt;.*?&lt;div class="content"&gt;(.*?)&lt;/div&gt;.*?&lt;i class="number"&gt;(.*?)&lt;/i&gt;',re.S)
		items = re.findall(pattern,pageCode)
		#用来存储每页的段子们
		pageStories = []
		#遍历正则表达式匹配的信息
		for item in items:
			replaceBR = re.compile('&lt;br/&gt;')
			text = re.sub(replaceBR,"\n",item [1] )
			print item[0],text ,item [2]
			pageStories.append([item[0].strip(),text.strip(),item [2] .strip()])
		return pageStories
	
	#加载并提取页面的内容，加入到列表中
	def loadPage(self):
		#如果当前未看的页数少于2页，则加载新一页
		if self.enable == True:
			if len(self.stories) < 2:
				#获取新一页
				pageStories = self.getPageItems(self.pageIndex)
				#将该页的段子存放到全局list中
				if pageStories:
					self.stories.append(pageStories)
					#获取完之后页码索引加一，表示下次读取下一页
					self.pageIndex += 1
	
	#调用该方法，每次敲回车打印输出一个段子
	def getOneStory(self,pageStories,page):
		#遍历一页的段子
		for story in pageStories:
			#等待用户输入
			input = raw_input()
			#每当输入回车一次，判断一下是否要加载新页面
			self.loadPage()
			#如果输入Q则程序结束
			if input == "Q":
				self.enable = False
				return
			print u"第%d页\t发布人:%s\t赞:%s\n%s" %(page,story[0],story [2] ,story [1] )
	
	#开始方法
	def start(self):
		print u"正在读取糗事百科,按回车查看新段子，Q退出"
		#使变量为True，程序可以正常运行
		self.enable = True
		#先加载一页内容
		self.loadPage()
		#局部变量，控制当前读到了第几页
		nowPage = 0
		while self.enable:
			if len(self.stories)>0:
				#从全局list中获取一页的段子
				pageStories = self.stories[0]
				#当前读到的页数加一
				nowPage += 1
				#将全局list中第一个元素删除，因为已经取出
				del self.stories[0]
				#输出该页的段子
				self.getOneStory(pageStories,nowPage)
	
	
spider = QSBK()
spider.start()
			</pre>
        <h2 id="tag3">测试node爬虫的可用性</h2>
        <pre>
#nodeServer.js
var http = require("http");
 
// Utility function that downloads a URL and invokes
// callback with the data.
function download(url, callback) {
  http.get(url, function(res) {
    var data = "";
    res.on('data', function (chunk) {
      data += chunk;
    });
    res.on("end", function() {
      callback(data);
    });
  }).on("error", function() {
    callback(null);
  });
}
 
exports.download = download; 



#node_crawler.js
var cheerio = require("cheerio");

var server = require("./nodeServer");
 
var url = "http://v.163.com/special/opencourse/englishs1.html"
 
server.download(url, function(data) {
  if (data) {
    //console.log(data);
 
    var $ = cheerio.load(data);
    $("a.downbtn").each(function(i, e) {
        console.log($(e).attr("href"));
    });
 
    console.log("done");
  } else {
      console.log("error");
  } 
}); 
			</pre>
        <h2 id="tag4">使用node.js获取慕课网node视频教程的标题</h2>
        <pre>
var http = require('http');
var cheerio = require('cheerio');
var url = 'http://www.imooc.com/learn/348';
function filter(html){
	var $ = cheerio.load(html);
	var chapters = $('.chapter');
	var courseData = [];

	chapters.each(function(item){
		var chapter = $(this);
		var chapterTitle = chapter.find('strong').text();
		var videos = chapter.find('.video').children('li');
		var chapterData = {
			chapterTitle: chapterTitle,
			videos:[],
		};
		videos.each(function(item){
			var video = $(this).find('.studyvideo');
			var videoTitle = video.text();
			var id = video.attr('href').split('video/')[1];
			chapterData.videos.push({
				title:videoTitle,
				id: id
			});
		});
		courseData.push(chapterData);

	});
	return courseData;
}
function printCourseInfo(course){
	course.forEach(function(item){
		var chapterTitle = item.chapterTitle;
		console.log(chapterTitle+'\n');
		item.videos.forEach(function(video){
			console.log(' ['+video.id+']'+video.title+'\n');
		});
	});
}
http.get(url,function(res){
	var html=' ';

	res.on('data',function(data){
		html+=data;
	});
	res.on('end',function(){
		var courseData = filter(html);
		console.log('success');
		printCourseInfo(courseData);
	});
}).on('error',function(){
	console.log('something wrong happen');
});
			</pre>
    </section>
    <footer>一个代码爱好者</footer>
</body>

</html>
